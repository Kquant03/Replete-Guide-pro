# Quantization

This is how we make models smaller and easier to run on lower-end hardware. It's not as complicated as the term makes it sound, I promise.